{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 12:05:26.095218: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import splitfolders\n",
    "import shutil\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/stanford-dogs-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750M/750M [10:46<00:00, 1.22MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/muhammadabdelmohsen/.cache/kagglehub/datasets/jessicali9530/stanford-dogs-dataset/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-dogs-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning & Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagesDir = \"/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/DogBreedsClassification/Images\"\n",
    "trainDir = \"/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/DogBreedsClassification/train\"\n",
    "testDir = \"/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/DogBreedsClassification/test\"\n",
    "valDir = \"/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/DogBreedsClassification/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in os.listdir(ImagesDir):\n",
    "    if i == \".DS_Store\":\n",
    "        continue\n",
    "    name = i.split('-', 1)[1]   # Split at first dash and take the second part\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dog Breeds Found: 124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'.DS_Store',\n",
       " 'Afghan_hound',\n",
       " 'African_hunting_dog',\n",
       " 'Airedale',\n",
       " 'American_Staffordshire_terrier',\n",
       " 'Appenzeller',\n",
       " 'Australian_terrier',\n",
       " 'Bedlington_terrier',\n",
       " 'Bernese_mountain_dog',\n",
       " 'Blenheim_spaniel',\n",
       " 'Border_collie',\n",
       " 'Border_terrier',\n",
       " 'Boston_bull',\n",
       " 'Bouvier_des_Flandres',\n",
       " 'Brabancon_griffon',\n",
       " 'Brittany_spaniel',\n",
       " 'Cardigan',\n",
       " 'Chesapeake_Bay_retriever',\n",
       " 'Chihuahua',\n",
       " 'Dandie_Dinmont',\n",
       " 'Doberman',\n",
       " 'English_foxhound',\n",
       " 'English_setter',\n",
       " 'English_springer',\n",
       " 'EntleBucher',\n",
       " 'Eskimo_dog',\n",
       " 'French_bulldog',\n",
       " 'German_shepherd',\n",
       " 'German_short-haired_pointer',\n",
       " 'Gordon_setter',\n",
       " 'Great_Dane',\n",
       " 'Great_Pyrenees',\n",
       " 'Greater_Swiss_Mountain_dog',\n",
       " 'Ibizan_hound',\n",
       " 'Irish_setter',\n",
       " 'Irish_terrier',\n",
       " 'Irish_water_spaniel',\n",
       " 'Irish_wolfhound',\n",
       " 'Italian_greyhound',\n",
       " 'Japanese_spaniel',\n",
       " 'Kerry_blue_terrier',\n",
       " 'Labrador_retriever',\n",
       " 'Lakeland_terrier',\n",
       " 'Leonberg',\n",
       " 'Lhasa',\n",
       " 'Maltese_dog',\n",
       " 'Mexican_hairless',\n",
       " 'Newfoundland',\n",
       " 'Norfolk_terrier',\n",
       " 'Norwegian_elkhound',\n",
       " 'Norwich_terrier',\n",
       " 'Old_English_sheepdog',\n",
       " 'Pekinese',\n",
       " 'Pembroke',\n",
       " 'Pomeranian',\n",
       " 'Rhodesian_ridgeback',\n",
       " 'Rottweiler',\n",
       " 'Saint_Bernard',\n",
       " 'Saluki',\n",
       " 'Samoyed',\n",
       " 'Scotch_terrier',\n",
       " 'Scottish_deerhound',\n",
       " 'Sealyham_terrier',\n",
       " 'Shetland_sheepdog',\n",
       " 'Shih-Tzu',\n",
       " 'Siberian_husky',\n",
       " 'Staffordshire_bullterrier',\n",
       " 'Sussex_spaniel',\n",
       " 'Tibetan_mastiff',\n",
       " 'Tibetan_terrier',\n",
       " 'Walker_hound',\n",
       " 'Weimaraner',\n",
       " 'Welsh_springer_spaniel',\n",
       " 'West_Highland_white_terrier',\n",
       " 'Yorkshire_terrier',\n",
       " 'affenpinscher',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'black-and-tan_coonhound',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'borzoi',\n",
       " 'boxer',\n",
       " 'briard',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly-coated_retriever',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'flat-coated_retriever',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'groenendael',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'schipperke',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'test',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'train',\n",
       " 'val',\n",
       " 'vizsla',\n",
       " 'whippet',\n",
       " 'wire-haired_fox_terrier'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Folders = set(os.listdir(ImagesDir))\n",
    "print(\"Unique Dog Breeds Found:\", len(Folders))\n",
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the folders in the foldersSet to the trainDir, testDir, valDir\n",
    "if not os.path.exists(trainDir):\n",
    "    os.makedirs(trainDir)\n",
    "if not os.path.exists(testDir):\n",
    "    os.makedirs(testDir)\n",
    "if not os.path.exists(valDir):\n",
    "    os.makedirs(valDir)\n",
    "# Create subdirectories for train, test, and validation sets dog breeds\n",
    "for folder in Folders:\n",
    "\n",
    "    if folder == \".DS_Store\":\n",
    "        continue\n",
    "    folderPath = os.path.join(ImagesDir, folder)\n",
    "    if not os.path.exists(os.path.join(trainDir, folder)):\n",
    "        os.makedirs(os.path.join(trainDir, folder))\n",
    "    if not os.path.exists(os.path.join(testDir, folder)):\n",
    "        os.makedirs(os.path.join(testDir, folder))\n",
    "    if not os.path.exists(os.path.join(valDir, folder)):\n",
    "        os.makedirs(os.path.join(valDir, folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed: Australian_terrier -> Train: 156, Val: 19, Test: 21\n",
      "Breed: toy_poodle -> Train: 120, Val: 15, Test: 16\n",
      "Breed: Great_Pyrenees -> Train: 170, Val: 21, Test: 22\n",
      "Breed: Maltese_dog -> Train: 201, Val: 25, Test: 26\n",
      "Breed: Norwich_terrier -> Train: 148, Val: 18, Test: 19\n",
      "Breed: whippet -> Train: 149, Val: 18, Test: 20\n",
      "Breed: Boston_bull -> Train: 145, Val: 18, Test: 19\n",
      "Breed: Irish_setter -> Train: 124, Val: 15, Test: 16\n",
      "Breed: Rottweiler -> Train: 121, Val: 15, Test: 16\n",
      "Breed: kelpie -> Train: 122, Val: 15, Test: 16\n",
      "Breed: schipperke -> Train: 123, Val: 15, Test: 16\n",
      "Breed: Leonberg -> Train: 168, Val: 21, Test: 21\n",
      "Breed: Welsh_springer_spaniel -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Pomeranian -> Train: 175, Val: 21, Test: 23\n",
      "Breed: Pekinese -> Train: 119, Val: 14, Test: 16\n",
      "Breed: Irish_wolfhound -> Train: 174, Val: 21, Test: 23\n",
      "Breed: Blenheim_spaniel -> Train: 150, Val: 18, Test: 20\n",
      "Breed: basenji -> Train: 167, Val: 20, Test: 22\n",
      "Breed: African_hunting_dog -> Train: 135, Val: 16, Test: 18\n",
      "Breed: komondor -> Train: 123, Val: 15, Test: 16\n",
      "Breed: Yorkshire_terrier -> Train: 131, Val: 16, Test: 17\n",
      "Breed: basset -> Train: 140, Val: 17, Test: 18\n",
      "Breed: Japanese_spaniel -> Train: 148, Val: 18, Test: 19\n",
      "Breed: standard_schnauzer -> Train: 124, Val: 15, Test: 16\n",
      "Breed: dhole -> Train: 120, Val: 15, Test: 15\n",
      "Breed: miniature_pinscher -> Train: 147, Val: 18, Test: 19\n",
      "Breed: Lhasa -> Train: 148, Val: 18, Test: 20\n",
      "Breed: Walker_hound -> Train: 122, Val: 15, Test: 16\n",
      "Breed: Kerry_blue_terrier -> Train: 143, Val: 17, Test: 19\n",
      "Breed: standard_poodle -> Train: 127, Val: 15, Test: 17\n",
      "Breed: Saint_Bernard -> Train: 136, Val: 17, Test: 17\n",
      "Breed: Chihuahua -> Train: 121, Val: 15, Test: 16\n",
      "Breed: Afghan_hound -> Train: 191, Val: 23, Test: 25\n",
      "Breed: Newfoundland -> Train: 156, Val: 19, Test: 20\n",
      "Breed: black-and-tan_coonhound -> Train: 127, Val: 15, Test: 17\n",
      "Breed: pug -> Train: 160, Val: 20, Test: 20\n",
      "Breed: Scottish_deerhound -> Train: 185, Val: 23, Test: 24\n",
      "Breed: cairn -> Train: 157, Val: 19, Test: 21\n",
      "Breed: malamute -> Train: 142, Val: 17, Test: 19\n",
      "Breed: beagle -> Train: 156, Val: 19, Test: 20\n",
      "Breed: vizsla -> Train: 123, Val: 15, Test: 16\n",
      "Breed: collie -> Train: 122, Val: 15, Test: 16\n",
      "Breed: Italian_greyhound -> Train: 145, Val: 18, Test: 19\n",
      "Breed: West_Highland_white_terrier -> Train: 135, Val: 16, Test: 18\n",
      "Breed: Brittany_spaniel -> Train: 121, Val: 15, Test: 16\n",
      "Breed: English_springer -> Train: 127, Val: 15, Test: 17\n",
      "Breed: affenpinscher -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Doberman -> Train: 120, Val: 15, Test: 15\n",
      "Breed: silky_terrier -> Train: 146, Val: 18, Test: 19\n",
      "Breed: Pembroke -> Train: 144, Val: 18, Test: 19\n",
      "Breed: Weimaraner -> Train: 128, Val: 16, Test: 16\n",
      "Breed: papillon -> Train: 156, Val: 19, Test: 21\n",
      "Breed: Norwegian_elkhound -> Train: 156, Val: 19, Test: 21\n",
      "Breed: Sussex_spaniel -> Train: 120, Val: 15, Test: 16\n",
      "Breed: soft-coated_wheaten_terrier -> Train: 124, Val: 15, Test: 17\n",
      "Breed: Shih-Tzu -> Train: 171, Val: 21, Test: 22\n",
      "Breed: Ibizan_hound -> Train: 150, Val: 18, Test: 20\n",
      "Breed: cocker_spaniel -> Train: 127, Val: 15, Test: 17\n",
      "Breed: flat-coated_retriever -> Train: 121, Val: 15, Test: 16\n",
      "Breed: American_Staffordshire_terrier -> Train: 131, Val: 16, Test: 17\n",
      "Breed: Rhodesian_ridgeback -> Train: 137, Val: 17, Test: 18\n",
      "Breed: Samoyed -> Train: 174, Val: 21, Test: 23\n",
      "Breed: Brabancon_griffon -> Train: 122, Val: 15, Test: 16\n",
      "Breed: groenendael -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Shetland_sheepdog -> Train: 125, Val: 15, Test: 17\n",
      "Breed: Bouvier_des_Flandres -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Lakeland_terrier -> Train: 157, Val: 19, Test: 21\n",
      "Breed: Saluki -> Train: 160, Val: 20, Test: 20\n",
      "Breed: miniature_poodle -> Train: 124, Val: 15, Test: 16\n",
      "Breed: Tibetan_terrier -> Train: 164, Val: 20, Test: 22\n",
      "Breed: Eskimo_dog -> Train: 120, Val: 15, Test: 15\n",
      "Breed: golden_retriever -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Staffordshire_bullterrier -> Train: 124, Val: 15, Test: 16\n",
      "Breed: giant_schnauzer -> Train: 125, Val: 15, Test: 17\n",
      "Breed: Bedlington_terrier -> Train: 145, Val: 18, Test: 19\n",
      "Breed: miniature_schnauzer -> Train: 123, Val: 15, Test: 16\n",
      "Breed: Border_collie -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Appenzeller -> Train: 120, Val: 15, Test: 16\n",
      "Breed: borzoi -> Train: 120, Val: 15, Test: 16\n",
      "Breed: Border_terrier -> Train: 137, Val: 17, Test: 18\n",
      "Breed: Siberian_husky -> Train: 153, Val: 19, Test: 20\n",
      "Breed: chow -> Train: 156, Val: 19, Test: 21\n",
      "Breed: curly-coated_retriever -> Train: 120, Val: 15, Test: 16\n",
      "Breed: Airedale -> Train: 161, Val: 20, Test: 21\n",
      "Breed: dingo -> Train: 124, Val: 15, Test: 17\n",
      "Breed: otterhound -> Train: 120, Val: 15, Test: 16\n",
      "Breed: keeshond -> Train: 126, Val: 15, Test: 17\n",
      "Breed: French_bulldog -> Train: 127, Val: 15, Test: 17\n",
      "Breed: toy_terrier -> Train: 137, Val: 17, Test: 18\n",
      "Breed: Sealyham_terrier -> Train: 161, Val: 20, Test: 21\n",
      "Breed: Labrador_retriever -> Train: 136, Val: 17, Test: 18\n",
      "Breed: Bernese_mountain_dog -> Train: 174, Val: 21, Test: 23\n",
      "Breed: German_shepherd -> Train: 121, Val: 15, Test: 16\n",
      "Breed: briard -> Train: 121, Val: 15, Test: 16\n",
      "Breed: Chesapeake_Bay_retriever -> Train: 133, Val: 16, Test: 18\n",
      "Breed: kuvasz -> Train: 120, Val: 15, Test: 15\n",
      "Breed: malinois -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Great_Dane -> Train: 124, Val: 15, Test: 17\n",
      "Breed: Norfolk_terrier -> Train: 137, Val: 17, Test: 18\n",
      "Breed: wire-haired_fox_terrier -> Train: 125, Val: 15, Test: 17\n",
      "Breed: Dandie_Dinmont -> Train: 144, Val: 18, Test: 18\n",
      "Breed: bull_mastiff -> Train: 124, Val: 15, Test: 17\n",
      "Breed: EntleBucher -> Train: 161, Val: 20, Test: 21\n",
      "Breed: Scotch_terrier -> Train: 126, Val: 15, Test: 17\n",
      "Breed: clumber -> Train: 120, Val: 15, Test: 15\n",
      "Breed: boxer -> Train: 120, Val: 15, Test: 16\n",
      "Breed: Cardigan -> Train: 124, Val: 15, Test: 16\n",
      "Breed: Tibetan_mastiff -> Train: 121, Val: 15, Test: 16\n",
      "Breed: bloodhound -> Train: 149, Val: 18, Test: 20\n",
      "Breed: Irish_water_spaniel -> Train: 120, Val: 15, Test: 15\n",
      "Breed: Old_English_sheepdog -> Train: 135, Val: 16, Test: 18\n",
      "Breed: bluetick -> Train: 136, Val: 17, Test: 18\n",
      "Breed: Irish_terrier -> Train: 135, Val: 16, Test: 18\n",
      "Breed: Mexican_hairless -> Train: 124, Val: 15, Test: 16\n",
      "Breed: English_setter -> Train: 128, Val: 16, Test: 17\n",
      "Breed: redbone -> Train: 118, Val: 14, Test: 16\n",
      "Breed: Gordon_setter -> Train: 122, Val: 15, Test: 16\n",
      "Breed: English_foxhound -> Train: 125, Val: 15, Test: 17\n",
      "Breed: German_short-haired_pointer -> Train: 121, Val: 15, Test: 16\n",
      "Breed: Greater_Swiss_Mountain_dog -> Train: 134, Val: 16, Test: 18\n",
      "✅ Done splitting!\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "for breed in os.listdir(ImagesDir):\n",
    "    breed_path = os.path.join(ImagesDir, breed)\n",
    "    if breed == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(breed_path) if os.path.isfile(os.path.join(breed_path, f))]\n",
    "    random.shuffle(images)\n",
    "\n",
    "    nTotal = len(images)\n",
    "    nTrain = int(0.8 * nTotal)\n",
    "    nVal = int(0.1 * nTotal)\n",
    "    nTest = nTotal - nTrain - nVal\n",
    "\n",
    "    train_files = images[:nTrain]\n",
    "    val_files = images[nTrain:nTrain + nVal]\n",
    "    test_files = images[nTrain + nVal:]\n",
    "\n",
    "    for split_name, split_files in zip(\n",
    "        [\"train\", \"val\", \"test\"],\n",
    "        [train_files, val_files, test_files]\n",
    "    ):\n",
    "        split_breed_dir = os.path.join(\"/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/DogBreedsClassification\", split_name, breed)\n",
    "        os.makedirs(split_breed_dir, exist_ok=True)\n",
    "\n",
    "        for file in split_files:\n",
    "            src = os.path.join(breed_path, file)\n",
    "            dst = os.path.join(split_breed_dir, file)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "    print(f\"Breed: {breed} -> Train: {nTrain}, Val: {nVal}, Test: {nTest}\")\n",
    "\n",
    "print(\"✅ Done splitting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "testData = ImageDataGenerator(rescale=1./255)\n",
    "valData = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16418 images belonging to 120 classes.\n",
      "Found 2153 images belonging to 120 classes.\n",
      "Found 2009 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "trainData = trainData.flow_from_directory(\n",
    "    trainDir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "testData = testData.flow_from_directory(\n",
    "    testDir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "valData = valData.flow_from_directory(\n",
    "    valDir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mSequential\u001b[49m([\n\u001b[32m      2\u001b[39m     Input(shape=(\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m3\u001b[39m)),\n\u001b[32m      3\u001b[39m     Conv2D(\u001b[32m32\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer = regularizers.l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m      4\u001b[39m     MaxPooling2D((\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m), padding=\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      5\u001b[39m     BatchNormalization(),\n\u001b[32m      6\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m     Conv2D(\u001b[32m64\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer=regularizers.l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m      9\u001b[39m     MaxPooling2D((\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m), padding=\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     10\u001b[39m     BatchNormalization(),\n\u001b[32m     11\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m     Conv2D(\u001b[32m128\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m), activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, padding=\u001b[33m'\u001b[39m\u001b[33msame\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer=regularizers.l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m     14\u001b[39m     MaxPooling2D((\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m), padding=\u001b[33m'\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     15\u001b[39m     BatchNormalization(),\n\u001b[32m     16\u001b[39m     Dropout(\u001b[32m0.2\u001b[39m),\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m     Flatten(),\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m     Dense(\u001b[32m256\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer=regularizers.l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m     21\u001b[39m     Dense(\u001b[32m128\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m, kernel_regularizer=regularizers.l2(\u001b[32m0.01\u001b[39m)),\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m ])\n",
      "\u001b[31mNameError\u001b[39m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(224, 224, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer = regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2,2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2,2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    MaxPooling2D((2,2), padding='valid'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Flatten(),\n",
    "\n",
    "    Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(patience=5, restore_best_weights=True, monitor=['val_loss'])\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0008),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadabdelmohsen/Desktop/ML & DL & LLM Projects/ML_NN_Env/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 120), output.shape=(None, 128)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalData\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearlyStopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML & DL & LLM Projects/ML_NN_Env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML & DL & LLM Projects/ML_NN_Env/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:669\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m    667\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m    668\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    670\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    671\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    672\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    673\u001b[39m         )\n\u001b[32m    675\u001b[39m output, from_logits = _get_logits(\n\u001b[32m    676\u001b[39m     output, from_logits, \u001b[33m\"\u001b[39m\u001b[33mSoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    677\u001b[39m )\n\u001b[32m    678\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 120), output.shape=(None, 128)"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    trainData,\n",
    "    validation_data=valData,\n",
    "    epochs=2,\n",
    "    callbacks=[earlyStopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_NN_Env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
